{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ›’ Retail & E-commerce Recommendation Engine\n",
    "#### (Now includes Section 4.3: Model Performance Comparison Table)\n",
    "\n",
    "This notebook builds baseline and session-based recommendation models, then compares their performance as per the project requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pyspark in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.0.0)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2025.7.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\admins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Admins\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\Admins\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy matplotlib scikit-learn torch pyspark kagglehub\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 132120576 bytes (172599398 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/retailrocket/ecommerce-dataset?dataset_version_number=2 (132120576/304719974) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291M/291M [00:16<00:00, 10.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Admins\\AppData\\Local\\Temp\\ipykernel_17300\\1710563975.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  user_hour = events.groupby(['visitorid', pd.Grouper(key='datetime', freq='H')]).size().reset_index(name='event_count')\n"
     ]
    }
   ],
   "source": [
    "# Load your data (adjust paths)\n",
    "path = kagglehub.dataset_download(\"retailrocket/ecommerce-dataset\")\n",
    "events = pd.read_csv(path+'/events.csv')\n",
    "# events.csv columns: timestamp, visitorid, event, itemid, transactionid\n",
    "\n",
    "# Remove duplicates\n",
    "events = events.drop_duplicates()\n",
    "\n",
    "# Timestamp to datetime\n",
    "events['datetime'] = pd.to_datetime(events['timestamp'], unit='ms')\n",
    "\n",
    "# Remove bots (users with >200 events in any hour)\n",
    "user_hour = events.groupby(['visitorid', pd.Grouper(key='datetime', freq='H')]).size().reset_index(name='event_count')\n",
    "bots = user_hour[user_hour['event_count'] > 200]['visitorid'].unique()\n",
    "events = events[~events['visitorid'].isin(bots)]\n",
    "\n",
    "# Filter users/items with >=5 interactions\n",
    "active_users = events['visitorid'].value_counts()[lambda x: x >= 5].index\n",
    "active_items = events['itemid'].value_counts()[lambda x: x >= 5].index\n",
    "events = events[events['visitorid'].isin(active_users) & events['itemid'].isin(active_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session split: new session if gap > 30min for a user\n",
    "events = events.sort_values(['visitorid', 'datetime'])\n",
    "events['session_id'] = (events.groupby('visitorid')['datetime']\n",
    "    .diff().gt(timedelta(minutes=30)).cumsum().astype(int))\n",
    "events['session_id'] = events['visitorid'].astype(str) + '_' + events['session_id'].astype(str)\n",
    "\n",
    "# Event encoding\n",
    "event_map = {'view': 1, 'addtocart': 3, 'transaction': 5}\n",
    "events['event_weight'] = events['event'].map(event_map)\n",
    "\n",
    "# Encode user/item\n",
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "events['user_idx'] = user_enc.fit_transform(events['visitorid'])\n",
    "events['item_idx'] = item_enc.fit_transform(events['itemid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Split (Temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = events['datetime'].max()\n",
    "train_cutoff = max_date - timedelta(weeks=2)\n",
    "val_cutoff = max_date - timedelta(weeks=1)\n",
    "train = events[events['datetime'] < train_cutoff]\n",
    "valid = events[(events['datetime'] >= train_cutoff) & (events['datetime'] < val_cutoff)]\n",
    "test = events[events['datetime'] >= val_cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Model: Most Popular Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = train['item_idx'].value_counts().index[:20].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GRU4Rec Session-based Model (PyTorch, demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 9.4879\n",
      "Epoch 2, Loss: 7.2098\n"
     ]
    }
   ],
   "source": [
    "# Build session sequences\n",
    "seq_df = (train.groupby('session_id')['item_idx'].apply(list).reset_index(name='seq'))\n",
    "seq_df = seq_df[seq_df['seq'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "class SessionDataset(Dataset):\n",
    "    def __init__(self, seqs, maxlen=10):\n",
    "        self.samples = []\n",
    "        for seq in seqs:\n",
    "            for i in range(1, len(seq)):\n",
    "                start = max(0, i - maxlen)\n",
    "                self.samples.append((seq[start:i], seq[i]))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        seq, label = self.samples[idx]\n",
    "        x = np.zeros(10, dtype=int)\n",
    "        x[-len(seq):] = seq[-10:]\n",
    "        return torch.LongTensor(x), torch.LongTensor([label])\n",
    "\n",
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self, n_items, emb_dim=50, hid_dim=100):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_items, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, n_items)\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        _, h = self.gru(emb)\n",
    "        out = self.fc(h.squeeze(0))\n",
    "        return out\n",
    "\n",
    "# Prepare PyTorch data\n",
    "sequences = seq_df['seq'].tolist()\n",
    "dataset = SessionDataset(sequences)\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRU4Rec(n_items=events['item_idx'].nunique()).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop (demo)\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Section 4.3: Model Performance Comparison Table\n",
    "We compare Most Popular and GRU4Rec using Precision@20, Recall@20, F1@20, and NDCG@20 on test sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metric functions ---\n",
    "def precision_at_k(y_true, y_pred, k=20):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    for pred, true in zip(y_pred, y_true):\n",
    "        if true in pred[:k]:\n",
    "            hits += 1\n",
    "        total += 1\n",
    "    return hits / total if total > 0 else 0\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k=20):\n",
    "    return precision_at_k(y_true, y_pred, k)  # for next-item prediction, recall==precision\n",
    "\n",
    "def f1_at_k(y_true, y_pred, k=20):\n",
    "    p = precision_at_k(y_true, y_pred, k)\n",
    "    r = recall_at_k(y_true, y_pred, k)\n",
    "    return 2 * p * r / (p + r + 1e-10)\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=20):\n",
    "    ndcg = 0\n",
    "    for pred, true in zip(y_pred, y_true):\n",
    "        if true in pred[:k]:\n",
    "            idx = pred[:k].index(true)\n",
    "            ndcg += 1 / np.log2(idx + 2)\n",
    "    return ndcg / len(y_true) if len(y_true) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare test sessions for evaluation ---\n",
    "test_sessions = [group['item_idx'].tolist() for _, group in test.groupby('session_id') if len(group) > 1]\n",
    "y_true = [items[-1] for items in test_sessions]\n",
    "\n",
    "# Most Popular prediction: same for all\n",
    "y_pred_pop = [most_popular for _ in test_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU4Rec predictions\n",
    "def predict_next(model, session, k=20):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inp = torch.LongTensor([session[-10:]]).to(device)\n",
    "        logits = model(inp)\n",
    "        topk = logits.cpu().numpy().argsort()[0][-k:][::-1]\n",
    "    return topk.tolist()\n",
    "\n",
    "y_pred_gru = []\n",
    "for items in test_sessions:\n",
    "    pred = predict_next(model, items[:-1], k=20)\n",
    "    y_pred_gru.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision@20</th>\n",
       "      <th>Recall@20</th>\n",
       "      <th>F1@20</th>\n",
       "      <th>NDCG@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Most Popular</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.008429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU4Rec</td>\n",
       "      <td>0.255544</td>\n",
       "      <td>0.255544</td>\n",
       "      <td>0.255544</td>\n",
       "      <td>0.191835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Precision@20  Recall@20     F1@20   NDCG@20\n",
       "0  Most Popular      0.017294   0.017294  0.017294  0.008429\n",
       "1       GRU4Rec      0.255544   0.255544  0.255544  0.191835"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 4.3 Table ---\n",
    "results = []\n",
    "results.append([\n",
    "    'Most Popular',\n",
    "    precision_at_k(y_true, y_pred_pop, 20),\n",
    "    recall_at_k(y_true, y_pred_pop, 20),\n",
    "    f1_at_k(y_true, y_pred_pop, 20),\n",
    "    ndcg_at_k(y_true, y_pred_pop, 20)\n",
    "])\n",
    "results.append([\n",
    "    'GRU4Rec',\n",
    "    precision_at_k(y_true, y_pred_gru, 20),\n",
    "    recall_at_k(y_true, y_pred_gru, 20),\n",
    "    f1_at_k(y_true, y_pred_gru, 20),\n",
    "    ndcg_at_k(y_true, y_pred_gru, 20)\n",
    "])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Precision@20', 'Recall@20', 'F1@20', 'NDCG@20'])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š The above table can be used to fill in your Section 4.3 Model Performance Comparison report.\n",
    "\n",
    "*Add more models (ALS, LightGBM, etc.) by extending the table.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
